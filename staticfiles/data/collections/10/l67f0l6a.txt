Novel descriptors of keypoints are proposed for matching (primarily) biological images. The descriptors incorporate characteristics of limited-size neighborhoods of keypoints. Descriptors are quantized into small vocabularies representing photometry of images (SIFT words) and geometry of their neighborhoods, so that significant distortions can be tolerated. In order to keep precision at a high level, Harris-Affine and Hessian-Affine detectors are independently applied. The retrieval results are accepted only if confirmed by both techniques. Using several test datasets, we preliminarily show that the method can retrieve semantically meaningful data from unknown and unpredictable images without any training or supervision. Low computational complexity of the method makes it a good candidate for scalable analysis of biological (e.g. zoological or botanical) visual databases.