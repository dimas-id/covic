The dynamical system is a mathematical concept motivated first by Newtonian mechanics. The state of the system is generally denoted by a point in an appropriately defined geometrical space. A dynamical system operates in time. Typically, we take the time set T to be the real line R (a continuous-time system) or the set of integers Z (a discrete-time system). We then formalize an autonomous system as a ordered pair (Q, g), where Q is the state space, and g : T × Q → Q is a function that assigns to each initial state x(0) ∈ Q the state x = g(t, x(0)), in which the system will be after a time interval t if it started in state x(0). A fundamental property of g, then, is the validity of the identity g(t + s, x(0)) ≡ g(s, g(t, x(0))) (4.1) for all states x, and times t, s. Loosely speaking g is a fixed rule which governs the motion of the system.