Viral mutation that escapes from human immunity remains a major obstacle to antiviral and vaccine development. While anticipating escape could aid rational therapeutic design, the complex rules governing viral escape are challenging to model. Here, we demonstrate an unprecedented ability to predict viral escape by using machine learning algorithms originally developed to model the complexity of human natural language. Our key conceptual advance is that predicting escape requires identifying mutations that preserve viral fitness, or “grammaticality,” and also induce high antigenic change, or “semantic change.” We develop viral language models for influenza hemagglutinin, HIV Env, and SARS-CoV-2 Spike that we use to construct antigenically meaningful semantic landscapes, perform completely unsupervised prediction of escape mutants, and learn structural escape patterns from sequence alone. More profoundly, we lay a promising conceptual bridge between natural language and viral evolution. One sentence summary Neural language models of semantic change and grammaticality enable unprecedented prediction of viral escape mutations.