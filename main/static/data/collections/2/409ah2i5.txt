BACKGROUND AND PURPOSE Low-porosity endoluminal devices for the treatment of intracranial aneurysms, also known as flow diverters, have been in experimental and clinical use for close to 10 years. Despite rigorous evidence of their safety and efficacy in well-controlled trials, a number of key factors concerning their use remain poorly defined. Among these, none has received more attention to date than the debate on how many devices are optimally required to achieve a safe, effective, and economical outcome. Additional, related questions concern device sizing relative to the parent artery and optimal method of deployment of the devices. While some or all of these issues may be ultimately answered on an empiric basis via subgroup analysis of growing treatment cohorts, we believe that careful in vitro examination of relevant device properties can also help guide its in vivo use. MATERIALS AND METHODS We conducted a number of benchtop experiments to investigate the varied porosity of Pipeline Embolization Devices deployed in a simulated range of parent vessel diameters and applied these results toward conceptualizing optimal treatment strategies of fusiform and wide-neck aneurysms. RESULTS The results of our studies confirm a predictable parabolic variability in device porosity based on the respective comparative sizes of the device and recipient artery, as well as device curvature. Even modest oversizing leads to a significant increase in porosity. CONCLUSIONS The experiments demonstrate various deleterious effects of device oversizing relative to the parent artery and provide strategies for addressing size mismatches when they are unavoidable.