BACKGROUND The aim of our study was to modify our previously developed laparoscopic ventral hernia (LVH) simulator to increase difficulty and then reassess validity and feasibility for using the simulator in a newly developed simulation-based continuing medical education course. METHODS Participants (N = 30) were practicing surgeons who signed up for a hands-on postgraduate laparoscopic hernia course. An LVH simulator, with prior validity evidence, was modified for the course to increase difficulty. Participants completed 1 of the 3 variations in hernia anatomy: incarcerated omentum, incarcerated bowel, and diffuse adhesions. During the procedure, course faculty and peer observers rated surgeon performance using Global Operative Assessment of Laparoscopic Skills-Incisional Hernia and Global Operative Assessment of Laparoscopic Skills rating scales with prior validity evidence. Rating scale reliability was reassessed for internal consistency. Peer and faculty raters' scores were compared. In addition, quality and completeness of the hernia repairs were rated. RESULTS Internal consistency on the general skills performance (peer α = .96, faculty α = .94) and procedure-specific performance (peer α = .91, faculty α = .88) scores were high. Peers were more lenient than faculty raters on all LVH items in both the procedure-specific skills and general skills ratings. Overall, participants scored poorly on the quality and completeness of their hernia repairs (mean = 3.90/16, standard deviation = 2.72), suggesting a mismatch between course attendees and hernia difficulty and identifying a learning need. CONCLUSIONS Simulation-based continuing medical education courses provide hands-on experiences that can positively affect clinical practice. Although our data appear to show a significant mismatch between clinical skill and simulator difficulty, these findings also underscore significant learning needs in the surgical community.